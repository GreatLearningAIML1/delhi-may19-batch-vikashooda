{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_Internal_Lab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84Q8JfvaeZZ6"
      },
      "source": [
        "## Linear Classifier in TensorFlow \n",
        "Using Low Level API in Eager Execution mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "14f73fa3-b990-4b6f-e52e-18cea525771c"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9JH3ZL1CKaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67b5fe01-543b-491d-c83d-6bb45fe826a6"
      },
      "source": [
        "tf.enable_eager_execution"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow.python.framework.ops.enable_eager_execution>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mjtb-EMcm5K0",
        "colab": {}
      },
      "source": [
        "#Enable Eager Execution if using tensflow version < 2.0\n",
        "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ec154a5c-0926-429a-ae13-5ec1ce4d51f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiObW4V4SIOz",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {}
      },
      "source": [
        "#data = pd.read_csv('/gdrive/My Drive/R6/Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDlFCHVYiNFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = pd.read_csv('/gdrive/My Drive/R6/prices.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3bb72b65-0eda-4e5c-cf9d-9d027cb717b5"
      },
      "source": [
        "data1.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(851264, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIHxhIoUkF9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b974ab4-594b-4964-ccfb-84ca238eec9d"
      },
      "source": [
        "data1.columns"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([u'date', u'symbol', u'open', u'close', u'low', u'high', u'volume'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "source": [
        "data1.drop(columns='date', inplace=True)\n",
        "data1.drop(columns='symbol', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "82eee250-39c0-4c0d-f1ac-70b180a93a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data1.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high   volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set\n",
        "Target 'Volume' has very high values. Divide 'Volume' by 1000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "539a1221-94a0-4620-b5a1-01c6a0ea2d03"
      },
      "source": [
        "df=data1.iloc[:1000]\n",
        "df.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkdEO46tqylm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "3d16f62c-cf50-41f2-d66c-dfacde31a6b4"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 5 columns):\n",
            "open      1000 non-null float64\n",
            "close     1000 non-null float64\n",
            "low       1000 non-null float64\n",
            "high      1000 non-null float64\n",
            "volume    1000 non-null int64\n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 39.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsZpZ_jx_X_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cdff6f07-4e5e-4e76-ed84-ea64555cfddc"
      },
      "source": [
        "df"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>115.510002</td>\n",
              "      <td>115.550003</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>116.059998</td>\n",
              "      <td>1098000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>116.459999</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>112.589996</td>\n",
              "      <td>117.070000</td>\n",
              "      <td>949600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>113.510002</td>\n",
              "      <td>114.379997</td>\n",
              "      <td>110.050003</td>\n",
              "      <td>115.029999</td>\n",
              "      <td>785300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>113.330002</td>\n",
              "      <td>112.529999</td>\n",
              "      <td>111.919998</td>\n",
              "      <td>114.879997</td>\n",
              "      <td>1093700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>113.660004</td>\n",
              "      <td>110.379997</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>115.870003</td>\n",
              "      <td>1523500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>109.059998</td>\n",
              "      <td>109.300003</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>111.599998</td>\n",
              "      <td>1653900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>109.730003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>110.580002</td>\n",
              "      <td>944300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>111.879997</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>112.949997</td>\n",
              "      <td>744900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>111.320000</td>\n",
              "      <td>110.120003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>114.629997</td>\n",
              "      <td>703800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>110.419998</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>107.300003</td>\n",
              "      <td>111.400002</td>\n",
              "      <td>563100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>110.769997</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>109.019997</td>\n",
              "      <td>112.570000</td>\n",
              "      <td>896100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>110.900002</td>\n",
              "      <td>112.580002</td>\n",
              "      <td>109.900002</td>\n",
              "      <td>112.970001</td>\n",
              "      <td>680400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>113.349998</td>\n",
              "      <td>114.470001</td>\n",
              "      <td>111.669998</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>749900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>112.900002</td>\n",
              "      <td>114.849998</td>\n",
              "      <td>574200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>113.250000</td>\n",
              "      <td>110.559998</td>\n",
              "      <td>109.750000</td>\n",
              "      <td>113.860001</td>\n",
              "      <td>694800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>113.379997</td>\n",
              "      <td>114.050003</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>114.639999</td>\n",
              "      <td>896300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>114.080002</td>\n",
              "      <td>115.709999</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>116.320000</td>\n",
              "      <td>956300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>115.120003</td>\n",
              "      <td>114.019997</td>\n",
              "      <td>109.709999</td>\n",
              "      <td>116.489998</td>\n",
              "      <td>997100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>113.300003</td>\n",
              "      <td>111.160004</td>\n",
              "      <td>110.459999</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>1200500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>111.169998</td>\n",
              "      <td>110.650002</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1725200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>106.730003</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>106.360001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1946000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>105.629997</td>\n",
              "      <td>107.129997</td>\n",
              "      <td>104.110001</td>\n",
              "      <td>109.260002</td>\n",
              "      <td>1319500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>108.559998</td>\n",
              "      <td>107.839996</td>\n",
              "      <td>107.070000</td>\n",
              "      <td>109.430000</td>\n",
              "      <td>922400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>109.110001</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>107.010002</td>\n",
              "      <td>111.300003</td>\n",
              "      <td>1185100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>110.830002</td>\n",
              "      <td>111.239998</td>\n",
              "      <td>107.970001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>921500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>19.240000</td>\n",
              "      <td>18.680000</td>\n",
              "      <td>18.530001</td>\n",
              "      <td>19.430000</td>\n",
              "      <td>9097500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>20.520000</td>\n",
              "      <td>20.290001</td>\n",
              "      <td>19.709999</td>\n",
              "      <td>20.549999</td>\n",
              "      <td>2242100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>12.950000</td>\n",
              "      <td>13.550000</td>\n",
              "      <td>12.720000</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>6205100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>76.059998</td>\n",
              "      <td>75.440002</td>\n",
              "      <td>75.349998</td>\n",
              "      <td>76.370003</td>\n",
              "      <td>864600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>19.620001</td>\n",
              "      <td>19.830000</td>\n",
              "      <td>19.480000</td>\n",
              "      <td>19.830000</td>\n",
              "      <td>709200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>88.000000</td>\n",
              "      <td>87.370003</td>\n",
              "      <td>87.139999</td>\n",
              "      <td>88.239998</td>\n",
              "      <td>1129600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>31.010000</td>\n",
              "      <td>30.959999</td>\n",
              "      <td>30.700001</td>\n",
              "      <td>31.120001</td>\n",
              "      <td>3449300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>35.900002</td>\n",
              "      <td>35.189999</td>\n",
              "      <td>34.930000</td>\n",
              "      <td>35.910000</td>\n",
              "      <td>7517100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>76.620003</td>\n",
              "      <td>77.650002</td>\n",
              "      <td>76.550003</td>\n",
              "      <td>77.790001</td>\n",
              "      <td>2356500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>25.799999</td>\n",
              "      <td>26.420000</td>\n",
              "      <td>25.719999</td>\n",
              "      <td>26.610001</td>\n",
              "      <td>4839200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>30.370001</td>\n",
              "      <td>31.059999</td>\n",
              "      <td>30.309999</td>\n",
              "      <td>31.110001</td>\n",
              "      <td>3684600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>23.120001</td>\n",
              "      <td>22.920000</td>\n",
              "      <td>22.740000</td>\n",
              "      <td>23.129999</td>\n",
              "      <td>14428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>39.790001</td>\n",
              "      <td>39.610001</td>\n",
              "      <td>39.090000</td>\n",
              "      <td>39.799999</td>\n",
              "      <td>1463300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>24.669997</td>\n",
              "      <td>25.140004</td>\n",
              "      <td>24.669997</td>\n",
              "      <td>25.160000</td>\n",
              "      <td>749600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>11.250000</td>\n",
              "      <td>11.770000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>11.790000</td>\n",
              "      <td>13355100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>1.630000</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>11538300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>17.020000</td>\n",
              "      <td>16.860001</td>\n",
              "      <td>16.790001</td>\n",
              "      <td>17.209999</td>\n",
              "      <td>9931300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>257.840004</td>\n",
              "      <td>256.079998</td>\n",
              "      <td>253.050003</td>\n",
              "      <td>257.959995</td>\n",
              "      <td>12906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>48.099998</td>\n",
              "      <td>48.150002</td>\n",
              "      <td>47.700001</td>\n",
              "      <td>48.369999</td>\n",
              "      <td>369900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>34.529999</td>\n",
              "      <td>34.430000</td>\n",
              "      <td>34.080002</td>\n",
              "      <td>34.750000</td>\n",
              "      <td>2701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>27.570000</td>\n",
              "      <td>27.790001</td>\n",
              "      <td>27.370000</td>\n",
              "      <td>27.919999</td>\n",
              "      <td>2627800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>14.200000</td>\n",
              "      <td>14.420000</td>\n",
              "      <td>14.120000</td>\n",
              "      <td>14.430000</td>\n",
              "      <td>3258700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>19.900000</td>\n",
              "      <td>19.580000</td>\n",
              "      <td>19.330000</td>\n",
              "      <td>20.059999</td>\n",
              "      <td>5206100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>62.660000</td>\n",
              "      <td>62.299999</td>\n",
              "      <td>62.189999</td>\n",
              "      <td>62.750000</td>\n",
              "      <td>7099000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>29.219999</td>\n",
              "      <td>28.719999</td>\n",
              "      <td>28.629999</td>\n",
              "      <td>29.309999</td>\n",
              "      <td>7795500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>63.310001</td>\n",
              "      <td>63.590000</td>\n",
              "      <td>63.240002</td>\n",
              "      <td>63.639999</td>\n",
              "      <td>2133200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>27.160000</td>\n",
              "      <td>26.990000</td>\n",
              "      <td>26.680000</td>\n",
              "      <td>27.299999</td>\n",
              "      <td>1982400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>28.320000</td>\n",
              "      <td>28.770000</td>\n",
              "      <td>28.010000</td>\n",
              "      <td>28.809999</td>\n",
              "      <td>37152800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>44.000000</td>\n",
              "      <td>44.799999</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>44.810001</td>\n",
              "      <td>6568600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>36.080002</td>\n",
              "      <td>37.139999</td>\n",
              "      <td>36.009998</td>\n",
              "      <td>37.230000</td>\n",
              "      <td>5604300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           open       close         low        high    volume\n",
              "0    123.430000  125.839996  122.309998  126.250000   2163600\n",
              "1    125.239998  119.980003  119.940002  125.540001   2386400\n",
              "2    116.379997  114.949997  114.930000  119.739998   2489500\n",
              "3    115.480003  116.620003  113.500000  117.440002   2006300\n",
              "4    117.010002  114.970001  114.089996  117.330002   1408600\n",
              "5    115.510002  115.550003  114.500000  116.059998   1098000\n",
              "6    116.459999  112.849998  112.589996  117.070000    949600\n",
              "7    113.510002  114.379997  110.050003  115.029999    785300\n",
              "8    113.330002  112.529999  111.919998  114.879997   1093700\n",
              "9    113.660004  110.379997  109.870003  115.870003   1523500\n",
              "10   109.059998  109.300003  108.320000  111.599998   1653900\n",
              "11   109.730003  110.000000  108.320000  110.580002    944300\n",
              "12   111.879997  111.949997  110.190002  112.949997    744900\n",
              "13   111.320000  110.120003  110.000000  114.629997    703800\n",
              "14   110.419998  111.000000  107.300003  111.400002    563100\n",
              "15   110.769997  110.709999  109.019997  112.570000    896100\n",
              "16   110.900002  112.580002  109.900002  112.970001    680400\n",
              "17   113.349998  114.470001  111.669998  114.589996    749900\n",
              "18   114.000000  114.500000  112.900002  114.849998    574200\n",
              "19   113.250000  110.559998  109.750000  113.860001    694800\n",
              "20   113.379997  114.050003  109.639999  114.639999    896300\n",
              "21   114.080002  115.709999  114.080002  116.320000    956300\n",
              "22   115.120003  114.019997  109.709999  116.489998    997100\n",
              "23   113.300003  111.160004  110.459999  113.300003   1200500\n",
              "24   111.169998  110.650002  109.639999  112.110001   1725200\n",
              "25   106.730003  107.519997  106.360001  112.110001   1946000\n",
              "26   105.629997  107.129997  104.110001  109.260002   1319500\n",
              "27   108.559998  107.839996  107.070000  109.430000    922400\n",
              "28   109.110001  110.769997  107.010002  111.300003   1185100\n",
              "29   110.830002  111.239998  107.970001  112.110001    921500\n",
              "..          ...         ...         ...         ...       ...\n",
              "970   19.240000   18.680000   18.530001   19.430000   9097500\n",
              "971   20.520000   20.290001   19.709999   20.549999   2242100\n",
              "972   12.950000   13.550000   12.720000   13.600000   6205100\n",
              "973   76.059998   75.440002   75.349998   76.370003    864600\n",
              "974   19.620001   19.830000   19.480000   19.830000    709200\n",
              "975   88.000000   87.370003   87.139999   88.239998   1129600\n",
              "976   31.010000   30.959999   30.700001   31.120001   3449300\n",
              "977   35.900002   35.189999   34.930000   35.910000   7517100\n",
              "978   76.620003   77.650002   76.550003   77.790001   2356500\n",
              "979   25.799999   26.420000   25.719999   26.610001   4839200\n",
              "980   30.370001   31.059999   30.309999   31.110001   3684600\n",
              "981   23.120001   22.920000   22.740000   23.129999  14428400\n",
              "982   39.790001   39.610001   39.090000   39.799999   1463300\n",
              "983   24.669997   25.140004   24.669997   25.160000    749600\n",
              "984   11.250000   11.770000   11.200000   11.790000  13355100\n",
              "985    1.630000    1.650000    1.600000    1.660000  11538300\n",
              "986   17.020000   16.860001   16.790001   17.209999   9931300\n",
              "987  257.840004  256.079998  253.050003  257.959995  12906000\n",
              "988   48.099998   48.150002   47.700001   48.369999    369900\n",
              "989   34.529999   34.430000   34.080002   34.750000   2701000\n",
              "990   27.570000   27.790001   27.370000   27.919999   2627800\n",
              "991   14.200000   14.420000   14.120000   14.430000   3258700\n",
              "992   19.900000   19.580000   19.330000   20.059999   5206100\n",
              "993   62.660000   62.299999   62.189999   62.750000   7099000\n",
              "994   29.219999   28.719999   28.629999   29.309999   7795500\n",
              "995   63.310001   63.590000   63.240002   63.639999   2133200\n",
              "996   27.160000   26.990000   26.680000   27.299999   1982400\n",
              "997   28.320000   28.770000   28.010000   28.809999  37152800\n",
              "998   44.000000   44.799999   43.750000   44.810001   6568600\n",
              "999   36.080002   37.139999   36.009998   37.230000   5604300\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4LE4U8lTdQJq",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChXsRe81uGPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=df[df.columns[0:4]]\n",
        "Y=df[\"volume\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ibjYXQumub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X,test_X,train_Y,test_Y=train_test_split(X,Y,test_size=0.30,random_state=1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYK-aUuLbrz2"
      },
      "source": [
        "#### Convert Training and Test Data to numpy float32 arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBBERWF3DH85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ao-S0tQGcncz",
        "colab": {}
      },
      "source": [
        "train_X = np.array(train_X).astype('float32')\n",
        "train_Y = np.array(train_Y).astype('float32')\n",
        "test_Y = np.array(test_Y).astype('float32')\n",
        "test_X = np.array(test_X).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db8nXX4uxI0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7053e97c-36a3-4765-b541-9f72e95d9776"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq971sSMxO9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9449f28-0b67-431c-dbe5-5c57d1963306"
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHDuLudwxthz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ac83eda-505b-45d6-d08b-24d028d88f40"
      },
      "source": [
        "train_Y.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcTgOmVB94RF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b05b1d0-e971-4db3-8d85-0044860c65af"
      },
      "source": [
        "test_X.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "im1ZegbDdKgv"
      },
      "source": [
        "### Normalize the data\n",
        "You can use Normalizer from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "transformer = Normalizer()\n",
        "train_X = transformer.fit_transform(train_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iULEix_HD7T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_X = transformer.transform(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "## Building the Model in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "w = tf.zeros(shape=(4,1))\n",
        "b = tf.zeros(shape=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "2.Define a function to calculate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "def prediction(X, w, b):\n",
        "    \n",
        "    Xw_matmul = tf.matmul(X, w)\n",
        "    Y = tf.add(Xw_matmul, b)\n",
        "    \n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "3.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "def loss(Y_actual, Y_predicted):\n",
        "    \n",
        "    diff = Y_actual - Y_predicted\n",
        "    sqr = tf.square(diff)\n",
        "    avg = tf.reduce_mean(sqr)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "4.Function to train the Model\n",
        "\n",
        "1.   Record all the mathematical steps to calculate Loss\n",
        "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
        "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "source": [
        "def train(X, Y_actual, w, b, learning_rate=0.01):\n",
        "    \n",
        "    #Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:\n",
        "        \n",
        "        t.watch([w,b])\n",
        "        \n",
        "        current_prediction = prediction(X, w, b)\n",
        "        current_loss = loss(Y_actual, current_prediction)\n",
        "    \n",
        "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw, db = t.gradient(current_loss,[w, b])\n",
        "    \n",
        "    #Update Weights and Bias\n",
        "    w = w - learning_rate*dw\n",
        "    b = b - learning_rate*db\n",
        "    \n",
        "    return w,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Train the model for 100 epochs \n",
        "1. Observe the training loss at every iteration\n",
        "2. Observe Train loss at every 5th iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fff9446-2d34-4690-b572-5ce0ed3c4276"
      },
      "source": [
        "for i in range(100):\n",
        "    \n",
        "    w, b = train(train_X, train_Y, w, b, learning_rate=0.01)\n",
        "    print('Current Loss on iteration', i,loss(train_Y, prediction(train_X, w, b)))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Current Loss on iteration', 0, <tf.Tensor 'Mean_1:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 1, <tf.Tensor 'Mean_3:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 2, <tf.Tensor 'Mean_5:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 3, <tf.Tensor 'Mean_7:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 4, <tf.Tensor 'Mean_9:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 5, <tf.Tensor 'Mean_11:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 6, <tf.Tensor 'Mean_13:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 7, <tf.Tensor 'Mean_15:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 8, <tf.Tensor 'Mean_17:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 9, <tf.Tensor 'Mean_19:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 10, <tf.Tensor 'Mean_21:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 11, <tf.Tensor 'Mean_23:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 12, <tf.Tensor 'Mean_25:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 13, <tf.Tensor 'Mean_27:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 14, <tf.Tensor 'Mean_29:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 15, <tf.Tensor 'Mean_31:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 16, <tf.Tensor 'Mean_33:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 17, <tf.Tensor 'Mean_35:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 18, <tf.Tensor 'Mean_37:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 19, <tf.Tensor 'Mean_39:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 20, <tf.Tensor 'Mean_41:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 21, <tf.Tensor 'Mean_43:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 22, <tf.Tensor 'Mean_45:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 23, <tf.Tensor 'Mean_47:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 24, <tf.Tensor 'Mean_49:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 25, <tf.Tensor 'Mean_51:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 26, <tf.Tensor 'Mean_53:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 27, <tf.Tensor 'Mean_55:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 28, <tf.Tensor 'Mean_57:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 29, <tf.Tensor 'Mean_59:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 30, <tf.Tensor 'Mean_61:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 31, <tf.Tensor 'Mean_63:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 32, <tf.Tensor 'Mean_65:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 33, <tf.Tensor 'Mean_67:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 34, <tf.Tensor 'Mean_69:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 35, <tf.Tensor 'Mean_71:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 36, <tf.Tensor 'Mean_73:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 37, <tf.Tensor 'Mean_75:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 38, <tf.Tensor 'Mean_77:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 39, <tf.Tensor 'Mean_79:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 40, <tf.Tensor 'Mean_81:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 41, <tf.Tensor 'Mean_83:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 42, <tf.Tensor 'Mean_85:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 43, <tf.Tensor 'Mean_87:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 44, <tf.Tensor 'Mean_89:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 45, <tf.Tensor 'Mean_91:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 46, <tf.Tensor 'Mean_93:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 47, <tf.Tensor 'Mean_95:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 48, <tf.Tensor 'Mean_97:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 49, <tf.Tensor 'Mean_99:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 50, <tf.Tensor 'Mean_101:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 51, <tf.Tensor 'Mean_103:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 52, <tf.Tensor 'Mean_105:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 53, <tf.Tensor 'Mean_107:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 54, <tf.Tensor 'Mean_109:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 55, <tf.Tensor 'Mean_111:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 56, <tf.Tensor 'Mean_113:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 57, <tf.Tensor 'Mean_115:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 58, <tf.Tensor 'Mean_117:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 59, <tf.Tensor 'Mean_119:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 60, <tf.Tensor 'Mean_121:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 61, <tf.Tensor 'Mean_123:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 62, <tf.Tensor 'Mean_125:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 63, <tf.Tensor 'Mean_127:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 64, <tf.Tensor 'Mean_129:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 65, <tf.Tensor 'Mean_131:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 66, <tf.Tensor 'Mean_133:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 67, <tf.Tensor 'Mean_135:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 68, <tf.Tensor 'Mean_137:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 69, <tf.Tensor 'Mean_139:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 70, <tf.Tensor 'Mean_141:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 71, <tf.Tensor 'Mean_143:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 72, <tf.Tensor 'Mean_145:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 73, <tf.Tensor 'Mean_147:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 74, <tf.Tensor 'Mean_149:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 75, <tf.Tensor 'Mean_151:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 76, <tf.Tensor 'Mean_153:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 77, <tf.Tensor 'Mean_155:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 78, <tf.Tensor 'Mean_157:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 79, <tf.Tensor 'Mean_159:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 80, <tf.Tensor 'Mean_161:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 81, <tf.Tensor 'Mean_163:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 82, <tf.Tensor 'Mean_165:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 83, <tf.Tensor 'Mean_167:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 84, <tf.Tensor 'Mean_169:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 85, <tf.Tensor 'Mean_171:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 86, <tf.Tensor 'Mean_173:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 87, <tf.Tensor 'Mean_175:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 88, <tf.Tensor 'Mean_177:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 89, <tf.Tensor 'Mean_179:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 90, <tf.Tensor 'Mean_181:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 91, <tf.Tensor 'Mean_183:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 92, <tf.Tensor 'Mean_185:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 93, <tf.Tensor 'Mean_187:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 94, <tf.Tensor 'Mean_189:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 95, <tf.Tensor 'Mean_191:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 96, <tf.Tensor 'Mean_193:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 97, <tf.Tensor 'Mean_195:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 98, <tf.Tensor 'Mean_197:0' shape=() dtype=float32>)\n",
            "('Current Loss on iteration', 99, <tf.Tensor 'Mean_199:0' shape=() dtype=float32>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7d8ee1f-3c29-4594-93e0-9fbc634721cc"
      },
      "source": [
        "w.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(4), Dimension(1)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc948ab4-2628-4e5f-af39-3584b19380c6"
      },
      "source": [
        "b.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(1)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERq9GOKKciho"
      },
      "source": [
        "### Model Prediction on 1st Examples in Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKGvUWahcihp",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "## Classification using tf.Keras\n",
        "\n",
        "In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O0g6lorycihf"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6xFvb5sRcihg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAB--Qdwcihm"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJr5dYnocihm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D95nY5ILcihj"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyMQoLMucihj",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b22qpC5xcihr"
      },
      "source": [
        "###  Building Model in tf.keras\n",
        "\n",
        "Build a Linear Classifier model  <br>\n",
        "1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n",
        "2. Apply Softmax on Dense Layer outputs <br>\n",
        "3. Use SGD as Optimizer\n",
        "4. Use categorical_crossentropy as loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hov_UFnUciht",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T5FdzqIKcihw"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4qLEdHPscihx",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-SgSSdRcih5"
      },
      "source": [
        "### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBgKZkhkcih6",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P32ASP1Vjt0a"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8rd0jjAjyTR",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XiipRpe7rbVh"
      },
      "source": [
        "### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n",
        "\n",
        "Does it perform better than Linear Classifier? What could be the reason for difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5Du3lubr4sA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}