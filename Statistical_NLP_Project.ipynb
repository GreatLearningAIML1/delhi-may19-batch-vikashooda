{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Statistical_NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JBAiBjyy-MMH",
        "outputId": "866bc1b0-b67c-45b0-e398-d1c92e847f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WqYamScL9cIr",
        "colab": {}
      },
      "source": [
        "#Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NKQDDkSX9rTV"
      },
      "source": [
        "1. Load the dataset (5 points)\n",
        "\n",
        "  Tip: As the dataset is large, use fewer rows. Check what is working well on     your machine and decide accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tHlc4dL49_TS",
        "outputId": "53b4e6ab-522d-4094-e913-cab20b5283b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# Reading the data \n",
        "corpus_df = pd.read_csv(\"/content/drive/My Drive/blogtext.csv\")\n",
        "corpus_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>14,May,2004</td>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>13,May,2004</td>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>11,June,2004</td>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>I had an interesting conversation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>Somehow Coca-Cola has a way of su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>If anything, Korea is a country o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>Take a read of this news article ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>09,June,2004</td>\n",
              "      <td>I surf the English news sites a l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                               text\n",
              "0  2059027  ...             Info has been found (+/- 100 pages,...\n",
              "1  2059027  ...             These are the team members:   Drewe...\n",
              "2  2059027  ...             In het kader van kernfusie op aarde...\n",
              "3  2059027  ...                   testing!!!  testing!!!          \n",
              "4  3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
              "5  3581210  ...               I had an interesting conversation...\n",
              "6  3581210  ...               Somehow Coca-Cola has a way of su...\n",
              "7  3581210  ...               If anything, Korea is a country o...\n",
              "8  3581210  ...               Take a read of this news article ...\n",
              "9  3581210  ...               I surf the English news sites a l...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tqKZRPaM--4I",
        "outputId": "9be42794-ed99-4a8d-89b5-37e47e51def3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "corpus_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(681284, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GimUo9cT_Bai",
        "outputId": "f698c792-5e27-41bc-e38d-be588f693848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Taking only initial 3k rows to initial pre processing & training\n",
        "corpus_df_sample = corpus_df[:3000]\n",
        "print(corpus_df_sample.shape)\n",
        "corpus_df_sample[\"text\"].loc[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'           Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.         '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1rOwR5je_nQD"
      },
      "source": [
        "2. Preprocess rows of the “text” column (7.5 points)\n",
        "\n",
        "a. Remove unwanted characters\n",
        "\n",
        "b. Convert text to lowercase\n",
        "\n",
        "c. Remove unwanted spaces\n",
        "\n",
        "d. Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9HD0cVem_km5",
        "outputId": "b901cdce-b351-464c-9485-b8c259ea11f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#Removing unwanted / special characters\n",
        "corpus_df_sample['text'] = corpus_df_sample['text'].str.replace('[^A-Za-z]',' ')\n",
        "corpus_df_sample[\"text\"].loc[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'           Info has been found          pages  and     MB of  pdf files  Now i have to wait untill our team leader has processed it and learns html          '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ln_JwJjP_bvK",
        "outputId": "913ecefd-e66f-4fca-a498-bb1cbf7d5876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Coverting to lower case\n",
        "corpus_df_sample['text'] = corpus_df_sample['text'].str.lower()\n",
        "corpus_df_sample[\"text\"].loc[0]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'           info has been found          pages  and     mb of  pdf files  now i have to wait untill our team leader has processed it and learns html          '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qozw0tAL_3Iu",
        "outputId": "d0a824d5-340e-41c8-9fad-0ae4fac060e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#Removing spaces\n",
        "corpus_df_sample[\"text\"] = corpus_df_sample[\"text\"].str.strip()\n",
        "corpus_df_sample[\"text\"].loc[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'info has been found          pages  and     mb of  pdf files  now i have to wait untill our team leader has processed it and learns html'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ltAwvh9k_8gc",
        "outputId": "14c5dae3-69eb-413e-e7c8-afb7c3556ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# splitting each row of text data into individual words.\n",
        "# So it can be iterated through to remove only stopwords in next steps.\n",
        "corpus_df_sample[\"text\"] = corpus_df_sample[\"text\"].str.split()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O47jti_lAj2n",
        "outputId": "d4c1e9d6-1330-44bd-90ff-29d7a77cf50f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UU2Rv6rxATh_",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EhbH2ZhTAGXn",
        "colab": {}
      },
      "source": [
        "#Removing stop words\n",
        "stop = stopwords.words('english')\n",
        "def removestopwords(y):   # Function definition\n",
        " stopwordremoved = [w for w in y if w not in stop]\n",
        " return(\" \".join(stopwordremoved))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yxc7qf4zAOfx",
        "outputId": "ad883826-fd38-43c5-d1dc-8e678f5dffcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_column_size = corpus_df_sample[\"text\"].size\n",
        "print(\"text column size :\", text_column_size)\n",
        "\n",
        "# Initialize an empty list to hold the text after stop word removal\n",
        "cleaner_corpus_df_sample_text = []\n",
        "\n",
        "# Loop over each text\n",
        "for i in range( 0, text_column_size):\n",
        "    cleaner_corpus_df_sample_text.append(removestopwords(corpus_df_sample[\"text\"][i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text column size : 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7rXiarbsAuNS",
        "outputId": "b17f9ff6-5a40-40a5-8cc4-adc296ec3a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cleaner_corpus_df_sample_text[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ah korean language looks difficult first figure read hanguel korea surprisingly easy learn alphabet characters seems easy vocabulary starts oh backwards us sentence structure yikes luckily many options us slow witted foreigners take language course could list urllink joongang article says lot resources urllink well guy motivation jeon ji hyun latest something actually star movies cfs hear means commercial feature positive saw latest movie sunday night hard describe name english version windstruck korean version yeochinso short ne yeojachingu rul sogayhamnida like introduce girlfriend surprisingly titles make sense like website korean english looks quite good actually urllink movie shown theatres subtitles special times info urllink list many theatres seoul click urllink urllink great reason learn korean already married went foreigners well local korean national course korean take picture put urllink movie hof bar update bud mine passed urllink link giordano ad apparently aired korea nothing xxx sensibilities sort'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3_LGq6jvAx5T",
        "outputId": "0b8ccf7b-528b-4f23-c910-a466c4810da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "#Replace text column with cleaner_corpus_df_sample_text \n",
        "corpus_df_sample[\"text\"] = cleaner_corpus_df_sample_text\n",
        "corpus_df_sample[\"text\"][10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ah korean language looks difficult first figure read hanguel korea surprisingly easy learn alphabet characters seems easy vocabulary starts oh backwards us sentence structure yikes luckily many options us slow witted foreigners take language course could list urllink joongang article says lot resources urllink well guy motivation jeon ji hyun latest something actually star movies cfs hear means commercial feature positive saw latest movie sunday night hard describe name english version windstruck korean version yeochinso short ne yeojachingu rul sogayhamnida like introduce girlfriend surprisingly titles make sense like website korean english looks quite good actually urllink movie shown theatres subtitles special times info urllink list many theatres seoul click urllink urllink great reason learn korean already married went foreigners well local korean national course korean take picture put urllink movie hof bar update bud mine passed urllink link giordano ad apparently aired korea nothing xxx sensibilities sort'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IoGTlyflBPTI",
        "outputId": "c9191b5d-c38d-4660-a990-b0a4e11745c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OAYqMm46A9wj",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JZdrBFqJBA1l",
        "outputId": "5ddfbfc2-51bd-4067-feb3-6615ce195a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#Lemmatization\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemm = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "    return(\" \".join(lemm)) \n",
        "\n",
        "corpus_df_sample[\"text\"] = corpus_df_sample.text.apply(lemmatize_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a-Ba7dD4Bk_y"
      },
      "source": [
        "3. As we want to make this into a multi-label classification problem, you are required to merge\n",
        "all the label columns together, so that we have all the labels together for a particular sentence\n",
        "(7.5 points)\n",
        "\n",
        "    a. Label columns to merge: “gender”, “age”, “topic”, “sign”\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9a8Q6fW6Bzcb",
        "outputId": "249c325f-322d-43e1-d36b-cee1ba0aba48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "corpus_df_sample.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>14,May,2004</td>\n",
              "      <td>info found page mb pdf file wait untill team l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>13,May,2004</td>\n",
              "      <td>team member drewes van der laag urllink mail r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                               text\n",
              "0  2059027  ...  info found page mb pdf file wait untill team l...\n",
              "1  2059027  ...  team member drewes van der laag urllink mail r...\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-dQpYBPLB31N",
        "outputId": "5af66a42-53d2-4653-f689-306c06a10a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "# mergeing 'gender', 'age', 'topic', 'sign'\n",
        "corpus_df_sample['age'] = corpus_df_sample['age'].astype(str)\n",
        "corpus_df_sample['labels'] = corpus_df_sample[['gender','age','topic','sign']].apply(lambda x: ','.join(x), axis = 1) \n",
        "corpus_df_sample_merged = corpus_df_sample.drop(labels = ['date','gender', 'age','topic','sign','id'], axis = 1)\n",
        "corpus_df_sample_merged.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>info found page mb pdf file wait untill team l...</td>\n",
              "      <td>male,15,Student,Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>team member drewes van der laag urllink mail r...</td>\n",
              "      <td>male,15,Student,Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
              "      <td>male,15,Student,Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>testing testing</td>\n",
              "      <td>male,15,Student,Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thanks yahoo toolbar capture url popups mean s...</td>\n",
              "      <td>male,33,InvestmentBanking,Aquarius</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                              labels\n",
              "0  info found page mb pdf file wait untill team l...                 male,15,Student,Leo\n",
              "1  team member drewes van der laag urllink mail r...                 male,15,Student,Leo\n",
              "2  het kader van kernfusie op aarde maak je eigen...                 male,15,Student,Leo\n",
              "3                                    testing testing                 male,15,Student,Leo\n",
              "4  thanks yahoo toolbar capture url popups mean s...  male,33,InvestmentBanking,Aquarius"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yi50J1QCB_q4",
        "outputId": "44a1918d-a967-4495-a768-d3792f74b9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "corpus_df_sample_merged.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Atz4iH-1mVtA"
      },
      "source": [
        "4. Separate features and labels, and split the data into training and testing (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F1_U8ez9mf65",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VS7VIjyTlQmK",
        "outputId": "65e811b6-5cbf-48d3-b4ec-8bb45c2f481c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feature = corpus_df_sample_merged['text']\n",
        "corpus_df_sample_merged['labels'] = corpus_df_sample_merged['labels'].str.lower()\n",
        "labels = corpus_df_sample_merged['labels']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(feature,labels, test_size = 0.33, random_state = 143)\n",
        "Y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2010,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hJw5KNj5my1M"
      },
      "source": [
        "5. Vectorize the features (5 points)\n",
        "\n",
        "a. Create a Bag of Words using count vectorizer\n",
        "\n",
        "i. Use ngram_range=(1, 2)\n",
        "\n",
        "ii. Vectorize training and testing features\n",
        "\n",
        "b. Print the term-document matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RfPy7Y7nnEmf",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6pO-MGwXmw63",
        "outputId": "5b7b71ea-48d4-4538-afcf-ab5dada40dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Creating Bag of words\n",
        "vectorizer = CountVectorizer(min_df = 2,ngram_range = (1,2),stop_words = \"english\")\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "print(\"X_train shape & sample\",X_train.shape)\n",
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape & sample (2010, 16018)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x16018 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 27 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FZTufoEnoNBX"
      },
      "source": [
        "6. Create a dictionary to get the count of every label i.e. the key will be label name and value will\n",
        "be the total count of the label. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sff3AWykoF_l",
        "outputId": "08ad14b9-4c41-4fde-eddc-e68c24fc3eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "vectorizer_labels = CountVectorizer(min_df = 1,ngram_range = (1,1),stop_words = \"english\")\n",
        "labels_vector = vectorizer_labels.fit_transform(labels)\n",
        "vectorizer_labels.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'14': 0,\n",
              " '15': 1,\n",
              " '16': 2,\n",
              " '17': 3,\n",
              " '23': 4,\n",
              " '24': 5,\n",
              " '25': 6,\n",
              " '26': 7,\n",
              " '27': 8,\n",
              " '33': 9,\n",
              " '34': 10,\n",
              " '35': 11,\n",
              " '37': 12,\n",
              " '39': 13,\n",
              " '41': 14,\n",
              " '44': 15,\n",
              " '45': 16,\n",
              " 'accounting': 17,\n",
              " 'aquarius': 18,\n",
              " 'aries': 19,\n",
              " 'arts': 20,\n",
              " 'banking': 21,\n",
              " 'businessservices': 22,\n",
              " 'cancer': 23,\n",
              " 'capricorn': 24,\n",
              " 'communications': 25,\n",
              " 'education': 26,\n",
              " 'engineering': 27,\n",
              " 'female': 28,\n",
              " 'gemini': 29,\n",
              " 'indunk': 30,\n",
              " 'internet': 31,\n",
              " 'investmentbanking': 32,\n",
              " 'leo': 33,\n",
              " 'libra': 34,\n",
              " 'libraries': 35,\n",
              " 'male': 36,\n",
              " 'media': 37,\n",
              " 'museums': 38,\n",
              " 'non': 39,\n",
              " 'pisces': 40,\n",
              " 'profit': 41,\n",
              " 'recreation': 42,\n",
              " 'sagittarius': 43,\n",
              " 'science': 44,\n",
              " 'scorpio': 45,\n",
              " 'sports': 46,\n",
              " 'student': 47,\n",
              " 'taurus': 48,\n",
              " 'technology': 49,\n",
              " 'virgo': 50}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNZN4vKi_JMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracing only key value from above dictionary, which contains unique labels. These set of labels will be used as classes in multilabelbinariser further.\n",
        "label_classes = []  \n",
        "for key in vectorizer_labels.vocabulary_.keys():\n",
        "    label_classes.append(key)\n",
        "    \n",
        "print(sorted(label_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pb2-1YpBoc_l"
      },
      "source": [
        "7. Transform the labels - (7.5 points)\n",
        "As we have noticed before, in this task each example can have multiple tags. To deal with\n",
        "such kind of prediction, we need to transform labels in a binary form and the prediction will be\n",
        "a mask of 0s and 1s. For this purpose, it is convenient to use MultiLabelBinarizer from sklearn\n",
        "\n",
        "a. Convert your train and test labels using MultiLabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PJpocg-DpHDd",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8Szoj4io-4U",
        "colab": {}
      },
      "source": [
        " # initialising multilabelbinariser with all unique possible classes\n",
        " mlb = MultiLabelBinarizer(classes = label_classes) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lwN_XVpPpCcw",
        "outputId": "43615f42-d3f4-4680-9d4e-c190c2e22f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Converting entire se of labels into format required by mlb\n",
        "labels = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in labels]]\n",
        "labels[30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male', '33', 'investmentbanking', 'aquarius']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F49Ix4sgpQvV",
        "outputId": "dc80fb86-7b1e-4492-996c-efe09f93af45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "labels_trans = mlb.fit(labels) # transforming entire set of lables\n",
        "labels_trans"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiLabelBinarizer(classes=['male', '15', 'student', 'leo', '33',\n",
              "                             'investmentbanking', 'aquarius', 'female', '14',\n",
              "                             'indunk', 'aries', '25', 'capricorn', '17',\n",
              "                             'gemini', '23', 'non', 'profit', 'cancer',\n",
              "                             'banking', '37', 'sagittarius', '26', '24',\n",
              "                             'scorpio', '27', 'education', '45', 'engineering',\n",
              "                             'libra', ...],\n",
              "                    sparse_output=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWd3VVhKpR0y",
        "outputId": "4e0601d4-b5f3-4271-a2d6-60f9e677dc68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Convert Y_train into a format as required by mlb \n",
        "Y_train = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in Y_train]]\n",
        "Y_train[30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male', '24', 'engineering', 'libra']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C8-cQVLppWtq",
        "outputId": "1463a7e5-fb96-41b8-f6d4-e53674761332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "Y_train_trans = mlb.transform(Y_train) # transforming Train lables using mlb which is trained on all possible unnique labels on entire data set\n",
        "Y_train_trans[30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) ['communicationsmedia', 'museumslibraries', 'nonprofit', 'sportsrecreation'] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OPL_JCbXpdnZ",
        "outputId": "0e824ef1-1953-473d-c61a-28a15fe40cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#Convert Y_test into a format as required by mlb \n",
        "Y_test = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in Y_test]]\n",
        "Y_test_trans = mlb.transform(Y_test) # transforming test labels.\n",
        "print(Y_test[30])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['male', '35', 'technology', 'aries']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) ['communicationsmedia', 'museumslibraries', 'nonprofit', 'sportsrecreation'] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lL98HGiops7s"
      },
      "source": [
        "8. Choose a classifier - (5 points)\n",
        "In this task, we suggest using the One-vs-Rest approach, which is implemented in\n",
        "OneVsRestClassifier class. In this approach k classifiers (= number of tags) are trained. As a\n",
        "basic classifier, use LogisticRegression . It is one of the simplest methods, but often it\n",
        "performs good enough in text classification tasks. It might take some time because the\n",
        "number of classifiers to train is large.\n",
        "\n",
        "a. Use a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on\n",
        "every label\n",
        "\n",
        "(b. As One-vs-Rest approach might not have been discussed in the sessions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iws6PEShqIgs",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "buP0YHTGp1QU",
        "colab": {}
      },
      "source": [
        "clf = LogisticRegression(solver = 'lbfgs',max_iter = 1000)  # initiating the classifier\n",
        "#from sklearn.svm import SVC\n",
        "#clf = SVC(kernel = \"linear\")\n",
        "clf = OneVsRestClassifier(clf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SoijmROTqO2l"
      },
      "source": [
        "9. Fit the classifier, make predictions and get the accuracy (5 points)\n",
        "\n",
        "a. Print the following\n",
        "\n",
        "i. Accuracy score\n",
        "\n",
        "ii. F1 score\n",
        "\n",
        "iii. Average precision score\n",
        "\n",
        "iv. Average recall score\n",
        "\n",
        "v. Tip: Make sure you are familiar with all of them. How would you expect the\n",
        "things to work for the multi-label scenario? Read about micro/macro/weighted\n",
        "averaging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VMDoXiLMqNSy",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report,f1_score, accuracy_score, recall_score, precision_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AwjrCaKNqaTy",
        "outputId": "13e1a5cd-e22d-4a01-d039-959aad146c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "clf.fit(X_train,Y_train_trans) # Fitting on  train data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 16 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 17 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 33 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 34 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 36 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 37 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 45 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 46 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=1000,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='lbfgs', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "joaPdfHmqfq4",
        "outputId": "15523202-7dad-4d77-fdc6-20be1281a181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Train Accuracy:\",clf.score(X_train,Y_train_trans))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.972139303482587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PK-UsQ26qjeU",
        "colab": {}
      },
      "source": [
        "Y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Flo0HGCtqmWY",
        "outputId": "511183e1-5997-4ca0-aceb-c8cec4d2f48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "print(\"Test Accuracy:\" + str(accuracy_score(Y_test_trans, Y_pred)))\n",
        "print(\"F1: \" + str(f1_score(Y_test_trans, Y_pred, average='micro')))\n",
        "print(\"F1_macro: \" + str(f1_score(Y_test_trans, Y_pred, average='macro')))\n",
        "print(\"Precision: \" + str(precision_score(Y_test_trans, Y_pred, average='micro')))\n",
        "print(\"Precision_macro: \" + str(precision_score(Y_test_trans, Y_pred, average='macro')))\n",
        "print(\"Recall: \" + str(recall_score(Y_test_trans, Y_pred, average='micro')))\n",
        "print(\"Recall_macro: \" + str(recall_score(Y_test_trans, Y_pred, average='macro')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:0.5686868686868687\n",
            "F1: 0.7584394023242943\n",
            "F1_macro: 0.2777544085541704\n",
            "Precision: 0.8270971635485818\n",
            "Precision_macro: 0.42504160995159523\n",
            "Recall: 0.7003065917220235\n",
            "Recall_macro: 0.2290073113591835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rQe0oknsqxgd"
      },
      "source": [
        "10. Print true label and predicted label for any five examples (7.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PPqCydc5quRS",
        "colab": {}
      },
      "source": [
        "Y_pred_inv = mlb.inverse_transform(Y_pred)   # inverse transforming predited label data\n",
        "Y_test_trans_inv =  mlb.inverse_transform(Y_test_trans) # inverse transforming original test label data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXZhUvXO_JOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\" predicted :\",Y_pred_inv[25])\n",
        "print(\" Actual :\",Y_test_trans_inv[25])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}